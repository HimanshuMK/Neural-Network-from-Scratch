{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOwdpJ6oKZmHWuK9elfNkYM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HimanshuMK/Neural-Network-from-Scratch/blob/main/SocialMedia_vs_Emotion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1c4Yz3Zri0R"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset is from Kaggle\n",
        "`Social Media Usage and Emotional Well-Being` <br>\n",
        "Link: https://www.kaggle.com/datasets/emirhanai/social-media-usage-and-emotional-well-being"
      ],
      "metadata": {
        "id": "kC4_aeWQJk2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#testing on some Dataset\n",
        "df_train= pd.read_csv('/content/train.csv')\n",
        "df_test= pd.read_csv('/content/test.csv')\n",
        "print(df_train.shape)\n",
        "print(df_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ek4f2A16r1yb",
        "outputId": "2784e6b1-9613-4246-981a-d310e34a2690"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1001, 10)\n",
            "(103, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preprocessing"
      ],
      "metadata": {
        "id": "GRomYwf3sbrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_train.info())\n",
        "print(df_test.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WPAadzAsWQo",
        "outputId": "48fd488d-70a6-419a-ad3b-8d1b49e4987d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1001 entries, 0 to 1000\n",
            "Data columns (total 10 columns):\n",
            " #   Column                      Non-Null Count  Dtype  \n",
            "---  ------                      --------------  -----  \n",
            " 0   User_ID                     1001 non-null   object \n",
            " 1   Age                         1001 non-null   object \n",
            " 2   Gender                      1000 non-null   object \n",
            " 3   Platform                    1000 non-null   object \n",
            " 4   Daily_Usage_Time (minutes)  1000 non-null   float64\n",
            " 5   Posts_Per_Day               1000 non-null   float64\n",
            " 6   Likes_Received_Per_Day      1000 non-null   float64\n",
            " 7   Comments_Received_Per_Day   1000 non-null   float64\n",
            " 8   Messages_Sent_Per_Day       1000 non-null   float64\n",
            " 9   Dominant_Emotion            1000 non-null   object \n",
            "dtypes: float64(5), object(5)\n",
            "memory usage: 78.3+ KB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 103 entries, 0 to 102\n",
            "Data columns (total 10 columns):\n",
            " #   Column                      Non-Null Count  Dtype \n",
            "---  ------                      --------------  ----- \n",
            " 0   User_ID                     103 non-null    int64 \n",
            " 1   Age                         103 non-null    object\n",
            " 2   Gender                      103 non-null    object\n",
            " 3   Platform                    103 non-null    object\n",
            " 4   Daily_Usage_Time (minutes)  103 non-null    int64 \n",
            " 5   Posts_Per_Day               103 non-null    int64 \n",
            " 6   Likes_Received_Per_Day      103 non-null    int64 \n",
            " 7   Comments_Received_Per_Day   103 non-null    int64 \n",
            " 8   Messages_Sent_Per_Day       103 non-null    int64 \n",
            " 9   Dominant_Emotion            103 non-null    object\n",
            "dtypes: int64(6), object(4)\n",
            "memory usage: 8.2+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_train.isnull().sum())\n",
        "print(df_test.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDgR8jNMt2G8",
        "outputId": "f79899a0-b56f-4c1f-cefb-e2b339e6c03a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User_ID                       0\n",
            "Age                           0\n",
            "Gender                        1\n",
            "Platform                      1\n",
            "Daily_Usage_Time (minutes)    1\n",
            "Posts_Per_Day                 1\n",
            "Likes_Received_Per_Day        1\n",
            "Comments_Received_Per_Day     1\n",
            "Messages_Sent_Per_Day         1\n",
            "Dominant_Emotion              1\n",
            "dtype: int64\n",
            "User_ID                       0\n",
            "Age                           0\n",
            "Gender                        0\n",
            "Platform                      0\n",
            "Daily_Usage_Time (minutes)    0\n",
            "Posts_Per_Day                 0\n",
            "Likes_Received_Per_Day        0\n",
            "Comments_Received_Per_Day     0\n",
            "Messages_Sent_Per_Day         0\n",
            "Dominant_Emotion              0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = df_train.dropna()"
      ],
      "metadata": {
        "id": "dF8y7lMTt5xQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_train.shape)\n",
        "print(df_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q01y9BsTuVia",
        "outputId": "0e9ff3d9-70b5-4d53-ad65-2df815683cba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 10)\n",
            "(103, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_train['Gender'].unique())\n",
        "print(df_test['Gender'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qq26zj5iuYMN",
        "outputId": "616c8a85-204c-4bc4-eaa0-ca3dc6d62714"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Female' 'Male' 'Non-binary' '27' '24' '29' '33' '31' '22' '25' '28' '30'\n",
            " '23' '34' '26' '35' '21' '32']\n",
            "['Female' 'Non-binary' 'Male' '27' 'Marie']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_train['Age'].unique())\n",
        "print(df_test['Age'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZGvhZUYuzxM",
        "outputId": "5f2f61de-d4f5-406c-f971-59f0e114472c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['25' '30' '22' '28' '33' '21' '27' '24' '29' '31' '23' '26' '34' '35'\n",
            " '32' 'Male' 'Female' 'Non-binary']\n",
            "['27' '21' '28' '25' '24' '33' '32' '23' '35' '31' '34' '29' '22' '26'\n",
            " '30' 'Male']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# resolve issues with gender\n",
        "def clean_gender(gender_value):\n",
        "  try:\n",
        "    float(gender_value)\n",
        "    return np.nan\n",
        "  except ValueError:\n",
        "    return gender_value\n",
        "\n",
        "# clean Age column\n",
        "# resolve issues with gender\n",
        "def clean_age(age_value):\n",
        "  try:\n",
        "    float(age_value)\n",
        "    return age_value\n",
        "  except ValueError:\n",
        "    return np.nan\n"
      ],
      "metadata": {
        "id": "uheYFiyAucZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the function to the Gender column of training\n",
        "df_train['Gender'] = df_train['Gender'].apply(clean_gender)\n",
        "# Fill NaN values with a placeholder or drop them\n",
        "# Here we fill NaN values with 'Unknown'\n",
        "df_train['Gender'].fillna('Unknown', inplace=True)\n",
        "# Verify the unique values after cleaning\n",
        "print(df_train['Gender'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9TnhKzIux9O",
        "outputId": "f51b60ed-20e5-4ded-80ff-becd288278f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Female' 'Male' 'Non-binary' 'Unknown']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#same for testing\n",
        "df_test['Gender'] = df_test['Gender'].apply(clean_gender)\n",
        "df_test['Gender'].fillna('Unknown', inplace=True)\n",
        "df_test['Gender'] = df_test['Gender'].replace('Marie', 'Unknown')\n",
        "print(df_test['Gender'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnX-rLgBvHlu",
        "outputId": "46a262c7-a367-4497-ffbf-cb74b9c27340"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Female' 'Non-binary' 'Male' 'Unknown']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_train['Age'].unique())\n",
        "print(df_test['Age'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epsKk4tlvgUN",
        "outputId": "8416bd71-0156-4ab4-b876-18b251d60696"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['25' '30' '22' '28' '33' '21' '27' '24' '29' '31' '23' '26' '34' '35'\n",
            " '32' 'Male' 'Female' 'Non-binary']\n",
            "['27' '21' '28' '25' '24' '33' '32' '23' '35' '31' '34' '29' '22' '26'\n",
            " '30' 'Male']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the function to the Age column of training\n",
        "df_train['Age'] = df_train['Age'].apply(clean_age)\n",
        "# Handle NaN values\n",
        "df_train['Age'].fillna(df_train['Age'].median(), inplace=True)\n",
        "print(df_train['Age'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7lI-ZP2wLxu",
        "outputId": "a9b39d71-f5e5-4e90-bc66-11a5a2fa4052"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Age\n",
            "28      92\n",
            "27      92\n",
            "29      90\n",
            "27.0    76\n",
            "22      74\n",
            "26      66\n",
            "25      64\n",
            "24      64\n",
            "31      62\n",
            "33      56\n",
            "21      56\n",
            "30      48\n",
            "23      48\n",
            "35      38\n",
            "32      38\n",
            "34      36\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for testing\n",
        "df_test['Age'] = df_test['Age'].apply(clean_age)\n",
        "# Handle NaN values\n",
        "df_test['Age'].fillna(df_test['Age'].median(), inplace=True)\n",
        "print(df_test['Age'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFoDfXorw7At",
        "outputId": "f1a4de52-328f-4bb1-8dff-90b36dbced00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Age\n",
            "28      13\n",
            "27      12\n",
            "23      11\n",
            "31      10\n",
            "29      10\n",
            "26       8\n",
            "25       6\n",
            "24       6\n",
            "21       5\n",
            "32       5\n",
            "22       4\n",
            "33       3\n",
            "35       3\n",
            "34       3\n",
            "30       3\n",
            "27.0     1\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['Age'] = df_train['Age'].apply(lambda x: float(x))\n",
        "df_test['Age'] = df_test['Age'].apply(lambda x: float(x))\n",
        "print(df_train['Age'].unique())\n",
        "print(df_test['Age'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIEKlcfkwPGG",
        "outputId": "8f592448-2e8a-49af-94b3-e18a1903a550"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[25. 30. 22. 28. 33. 21. 27. 24. 29. 31. 23. 26. 34. 35. 32.]\n",
            "[27. 21. 28. 25. 24. 33. 32. 23. 35. 31. 34. 29. 22. 26. 30.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#seeing categorical items\n",
        "cat_train = df_train.select_dtypes(include=['object']).columns.tolist()\n",
        "print(cat_train)\n",
        "cat_test = df_test.select_dtypes(include=['object']).columns.tolist()\n",
        "print(cat_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmWeBIoIxKkr",
        "outputId": "05e93e78-a5dc-40be-b813-e4ddc575eb1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['User_ID', 'Gender', 'Platform', 'Dominant_Emotion']\n",
            "['Gender', 'Platform', 'Dominant_Emotion']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = df_train.drop(columns=['User_ID'])\n",
        "df_test = df_test.drop(columns=['User_ID'])"
      ],
      "metadata": {
        "id": "rQnwsFOPxVbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#seeing categorical items\n",
        "cat_train = df_train.select_dtypes(include=['object']).columns.tolist()\n",
        "print(cat_train)\n",
        "cat_test = df_test.select_dtypes(include=['object']).columns.tolist()\n",
        "print(cat_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ou9ig383xq0X",
        "outputId": "79cf0c03-d557-4317-bfef-c521b094c779"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Gender', 'Platform', 'Dominant_Emotion']\n",
            "['Gender', 'Platform', 'Dominant_Emotion']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_train.columns)\n",
        "print(df_test.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIsnb2ElxtQv",
        "outputId": "8b10cfe3-f1a5-4573-c983-14fd2ba9824e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Age', 'Gender', 'Platform', 'Daily_Usage_Time (minutes)',\n",
            "       'Posts_Per_Day', 'Likes_Received_Per_Day', 'Comments_Received_Per_Day',\n",
            "       'Messages_Sent_Per_Day', 'Dominant_Emotion'],\n",
            "      dtype='object')\n",
            "Index(['Age', 'Gender', 'Platform', 'Daily_Usage_Time (minutes)',\n",
            "       'Posts_Per_Day', 'Likes_Received_Per_Day', 'Comments_Received_Per_Day',\n",
            "       'Messages_Sent_Per_Day', 'Dominant_Emotion'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.get_dummies(df_train, columns=['Gender'], drop_first=False)\n",
        "df_test = pd.get_dummies(df_test, columns=['Gender'], drop_first=False)"
      ],
      "metadata": {
        "id": "mnFaSneCxvqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_train.columns)\n",
        "print(df_test.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NRSq-fUyogf",
        "outputId": "2f8a9fb0-0017-470d-9b7c-43dc43096eb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Age', 'Platform', 'Daily_Usage_Time (minutes)', 'Posts_Per_Day',\n",
            "       'Likes_Received_Per_Day', 'Comments_Received_Per_Day',\n",
            "       'Messages_Sent_Per_Day', 'Dominant_Emotion', 'Gender_Female',\n",
            "       'Gender_Male', 'Gender_Non-binary', 'Gender_Unknown'],\n",
            "      dtype='object')\n",
            "Index(['Age', 'Platform', 'Daily_Usage_Time (minutes)', 'Posts_Per_Day',\n",
            "       'Likes_Received_Per_Day', 'Comments_Received_Per_Day',\n",
            "       'Messages_Sent_Per_Day', 'Dominant_Emotion', 'Gender_Female',\n",
            "       'Gender_Male', 'Gender_Non-binary', 'Gender_Unknown'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for training\n",
        "df_train['Gender_Female'] = df_train['Gender_Female'].astype(int)\n",
        "df_train['Gender_Male'] = df_train['Gender_Male'].astype(int)\n",
        "df_train['Gender_Non-binary'] = df_train['Gender_Non-binary'].astype(int)\n",
        "df_train['Gender_Unknown'] = df_train['Gender_Unknown'].astype(int)\n",
        "\n",
        "#for testing\n",
        "df_test['Gender_Female'] = df_test['Gender_Female'].astype(int)\n",
        "df_test['Gender_Male'] = df_test['Gender_Male'].astype(int)\n",
        "df_test['Gender_Non-binary'] = df_test['Gender_Non-binary'].astype(int)\n",
        "df_test['Gender_Unknown'] = df_test['Gender_Unknown'].astype(int)"
      ],
      "metadata": {
        "id": "Y1pFslnEy5Iy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#seeing categorical items\n",
        "cat_train = df_train.select_dtypes(include=['object']).columns.tolist()\n",
        "print(cat_train)\n",
        "cat_test = df_test.select_dtypes(include=['object']).columns.tolist()\n",
        "print(cat_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6ZqZ-KvzSUQ",
        "outputId": "4e31962a-2691-4d9d-d72b-b0e951df0bd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Platform', 'Dominant_Emotion']\n",
            "['Platform', 'Dominant_Emotion']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.get_dummies(df_train, columns=['Platform'], drop_first=False)\n",
        "df_test = pd.get_dummies(df_test, columns=['Platform'], drop_first=False)"
      ],
      "metadata": {
        "id": "TRCKptAOzU7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_train.columns)\n",
        "print(df_test.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mF4GBHUwzvyA",
        "outputId": "39253730-a991-4271-86a9-e7190e319b2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Age', 'Daily_Usage_Time (minutes)', 'Posts_Per_Day',\n",
            "       'Likes_Received_Per_Day', 'Comments_Received_Per_Day',\n",
            "       'Messages_Sent_Per_Day', 'Dominant_Emotion', 'Gender_Female',\n",
            "       'Gender_Male', 'Gender_Non-binary', 'Gender_Unknown',\n",
            "       'Platform_Facebook', 'Platform_Instagram', 'Platform_LinkedIn',\n",
            "       'Platform_Snapchat', 'Platform_Telegram', 'Platform_Twitter',\n",
            "       'Platform_Whatsapp'],\n",
            "      dtype='object')\n",
            "Index(['Age', 'Daily_Usage_Time (minutes)', 'Posts_Per_Day',\n",
            "       'Likes_Received_Per_Day', 'Comments_Received_Per_Day',\n",
            "       'Messages_Sent_Per_Day', 'Dominant_Emotion', 'Gender_Female',\n",
            "       'Gender_Male', 'Gender_Non-binary', 'Gender_Unknown',\n",
            "       'Platform_Facebook', 'Platform_Instagram', 'Platform_LinkedIn',\n",
            "       'Platform_Snapchat', 'Platform_Telegram', 'Platform_Twitter',\n",
            "       'Platform_Whatsapp'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_train.shape)\n",
        "print(df_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlKgHpMmzxVT",
        "outputId": "627f4a10-3d43-4cb2-8884-1bb14ecb8e43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 18)\n",
            "(103, 18)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['Platform_Facebook'] = df_train['Platform_Facebook'].astype(int)\n",
        "df_train['Platform_Instagram'] = df_train['Platform_Instagram'].astype(int)\n",
        "df_train['Platform_LinkedIn'] = df_train['Platform_LinkedIn'].astype(int)\n",
        "df_train['Platform_Snapchat'] = df_train['Platform_Snapchat'].astype(int)\n",
        "df_train['Platform_Telegram'] = df_train['Platform_Telegram'].astype(int)\n",
        "df_train['Platform_Twitter'] = df_train['Platform_Twitter'].astype(int)\n",
        "df_train['Platform_Whatsapp'] = df_train['Platform_Whatsapp'].astype(int)\n",
        "\n",
        "\n",
        "#for testing\n",
        "df_test['Platform_Facebook'] = df_test['Platform_Facebook'].astype(int)\n",
        "df_test['Platform_Instagram'] = df_test['Platform_Instagram'].astype(int)\n",
        "df_test['Platform_LinkedIn'] = df_test['Platform_LinkedIn'].astype(int)\n",
        "df_test['Platform_Snapchat'] = df_test['Platform_Snapchat'].astype(int)\n",
        "df_test['Platform_Telegram'] = df_test['Platform_Telegram'].astype(int)\n",
        "df_test['Platform_Twitter'] = df_test['Platform_Twitter'].astype(int)\n",
        "df_test['Platform_Whatsapp'] = df_test['Platform_Whatsapp'].astype(int)\n"
      ],
      "metadata": {
        "id": "97y6t6k5z1Ub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#seeing categorical items\n",
        "cat_train = df_train.select_dtypes(include=['object']).columns.tolist()\n",
        "print(cat_train)\n",
        "cat_test = df_test.select_dtypes(include=['object']).columns.tolist()\n",
        "print(cat_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goNv8qpv0OlY",
        "outputId": "96f88cf9-537b-4e0d-85ac-e8393a529e1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Dominant_Emotion']\n",
            "['Dominant_Emotion']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting Training and testing data"
      ],
      "metadata": {
        "id": "q1FlVJd0slKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = df_train.drop(columns=['Dominant_Emotion']) # Features\n",
        "y_train = df_train['Dominant_Emotion'] # Target\n",
        "\n",
        "X_test = df_test.drop(columns=['Dominant_Emotion']) # Features\n",
        "y_test = df_test['Dominant_Emotion'] # Target"
      ],
      "metadata": {
        "id": "kPRRLJGd0QxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.unique()"
      ],
      "metadata": {
        "id": "fltk1qMb0mfX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79537d23-8aee-41a3-eb94-efe1f0842a20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Happiness', 'Anger', 'Neutral', 'Anxiety', 'Boredom', 'Sadness'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Label Encoding"
      ],
      "metadata": {
        "id": "2K9o7BRdsr6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def label_encode(Emotion):\n",
        "  if(Emotion == 'Happiness'):\n",
        "    return 0\n",
        "  elif(Emotion == 'Anger'):\n",
        "    return 1\n",
        "  elif(Emotion == 'Neutral'):\n",
        "    return 2\n",
        "  elif(Emotion == 'Anxiety'):\n",
        "    return 3\n",
        "  elif(Emotion == 'Boredom'):\n",
        "    return 4\n",
        "  elif(Emotion == 'Sadness'):\n",
        "    return 5\n"
      ],
      "metadata": {
        "id": "JAOdfDf90oQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_train.apply(label_encode)\n",
        "y_test = y_test.apply(label_encode)\n"
      ],
      "metadata": {
        "id": "5e-g14v1mBvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)"
      ],
      "metadata": {
        "id": "05c_tWRIm72U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZKV2fKhZm9E7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Full Neural Network Code"
      ],
      "metadata": {
        "id": "ly6oRojHswZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dense layer\n",
        "class Layer_Dense :\n",
        "  # Layer initialization\n",
        "  def __init__ ( self , n_inputs , n_neurons ):\n",
        "    # Initialize weights and biases\n",
        "    self.weights = 0.1 * np.random.randn(n_inputs, n_neurons)\n",
        "    self.biases = np.zeros(( 1 , n_neurons))\n",
        "\n",
        "  # Forward pass\n",
        "  def forward ( self , inputs ):\n",
        "    # Remember input values\n",
        "    self.inputs = inputs\n",
        "    # Calculate output values from inputs, weights and biases\n",
        "    self.output = np.dot(inputs, self.weights) + self.biases\n",
        "\n",
        "  # Backward pass\n",
        "  def backward ( self , dvalues ):\n",
        "    # Gradients on parameters\n",
        "    self.dweights = np.dot(self.inputs.T, dvalues)\n",
        "    self.dbiases = np.sum(dvalues, axis = 0 , keepdims = True )\n",
        "    # Gradient on values\n",
        "    self.dinputs = np.dot(dvalues, self.weights.T)\n",
        "\n",
        "# Mean Squared Error Loss and its gradient\n",
        "def mse_loss(y_pred, y_true):\n",
        "    return np.mean((y_pred - y_true) ** 2)\n",
        "\n",
        "def mse_loss_gradient(y_pred, y_true):\n",
        "    return 2 * (y_pred - y_true) / y_true.size\n",
        "\n",
        "# ReLU activation\n",
        "class Activation_ReLU :\n",
        "  # Forward pass\n",
        "  def forward ( self , inputs ):\n",
        "    # Remember input values\n",
        "    self.inputs = inputs\n",
        "    # Calculate output values from inputs\n",
        "    self.output = np.maximum( 0 , inputs)\n",
        "\n",
        "  # Backward pass\n",
        "  def backward ( self , dvalues ):\n",
        "    # Since we need to modify original variable,\n",
        "    # let's make a copy of values first\n",
        "    self.dinputs = dvalues.copy()\n",
        "    # Zero gradient where input values were negative\n",
        "    self.dinputs[self.inputs <= 0 ] = 0\n",
        "\n",
        "#Softmax Activation\n",
        "class Activation_Softmax:\n",
        "    # Forward pass\n",
        "    def forward(self, inputs):\n",
        "        # Remember input values\n",
        "        self.inputs = inputs\n",
        "        # Subtract max value for numerical stability\n",
        "        exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
        "        # Normalize probabilities\n",
        "        probabilities = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
        "        self.output = probabilities\n",
        "\n",
        "    # Backward pass\n",
        "    def backward(self, dvalues):\n",
        "        # Create uninitialized array\n",
        "        self.dinputs = np.empty_like(dvalues)\n",
        "        # Enumerate outputs and gradients\n",
        "        for index, (single_output, single_dvalues) in enumerate(zip(self.output, dvalues)):\n",
        "            # Flatten output array\n",
        "            single_output = single_output.reshape(-1, 1)\n",
        "            # Calculate Jacobian matrix of the output and its gradient\n",
        "            jacobian_matrix = np.diagflat(single_output) - np.dot(single_output, single_output.T)\n",
        "            # Calculate sample-wise gradient\n",
        "            self.dinputs[index] = np.dot(jacobian_matrix, single_dvalues)\n",
        "\n",
        "\n",
        "#For Softmax Activation\n",
        "# Categorical Cross-Entropy Loss\n",
        "def categorical_crossentropy_loss(y_pred, y_true):\n",
        "    # Clip data to prevent division by 0\n",
        "    y_pred = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
        "    # Calculate loss\n",
        "    correct_confidences = y_pred[range(len(y_pred)), y_true]\n",
        "    return -np.mean(np.log(correct_confidences))\n",
        "\n",
        "\n",
        "# Gradient of Categorical Cross-Entropy Loss\n",
        "def categorical_crossentropy_loss_gradient(y_pred, y_true):\n",
        "    samples = len(y_pred)\n",
        "    labels = len(y_pred[0])\n",
        "\n",
        "    y_pred = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
        "\n",
        "    # Initialize the gradient\n",
        "    gradients = np.zeros_like(y_pred)\n",
        "\n",
        "    # Convert labels to one-hot if they are not\n",
        "    if len(y_true.shape) == 1:\n",
        "        y_true = np.eye(labels)[y_true]\n",
        "\n",
        "    # Calculate gradient\n",
        "    gradients = -y_true / y_pred\n",
        "    gradients = gradients / samples\n",
        "\n",
        "    return gradients\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Adam optimizer\n",
        "class Optimizer_Adam:\n",
        "\n",
        "    # Initialize optimizer - set settings\n",
        "    def __init__(self, learning_rate=0.001, decay=0., epsilon=1e-7,\n",
        "                 beta_1=0.9, beta_2=0.999):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.current_learning_rate = learning_rate\n",
        "        self.decay = decay\n",
        "        self.iterations = 0\n",
        "        self.epsilon = epsilon\n",
        "        self.beta_1 = beta_1\n",
        "        self.beta_2 = beta_2\n",
        "\n",
        "    # Call once before any parameter updates\n",
        "    def pre_update_params(self):\n",
        "        if self.decay:\n",
        "            self.current_learning_rate = self.learning_rate * (1. / (1. + self.decay * self.iterations))\n",
        "\n",
        "    # Update parameters\n",
        "    def update_params(self, layer):\n",
        "\n",
        "        # If layer does not contain cache arrays,\n",
        "        # create them filled with zeros\n",
        "        if not hasattr(layer, 'weight_cache'):\n",
        "            layer.weight_momentums = np.zeros_like(layer.weights)\n",
        "            layer.weight_cache = np.zeros_like(layer.weights)\n",
        "            layer.bias_momentums = np.zeros_like(layer.biases)\n",
        "            layer.bias_cache = np.zeros_like(layer.biases)\n",
        "\n",
        "        # Update momentum  with current gradients\n",
        "        layer.weight_momentums = self.beta_1 * layer.weight_momentums + (1 - self.beta_1) * layer.dweights\n",
        "        layer.bias_momentums = self.beta_1 * layer.bias_momentums + (1 - self.beta_1) * layer.dbiases\n",
        "\n",
        "        # Get corrected momentum\n",
        "        # self.iteration is 0 at first pass\n",
        "        # and we need to start with 1 here\n",
        "        weight_momentums_corrected = layer.weight_momentums / (1 - self.beta_1 ** (self.iterations + 1))\n",
        "        bias_momentums_corrected = layer.bias_momentums / (1 - self.beta_1 ** (self.iterations + 1))\n",
        "        # Update cache with squared current gradients\n",
        "        layer.weight_cache = self.beta_2 * layer.weight_cache + (1 - self.beta_2) * layer.dweights**2\n",
        "\n",
        "        layer.bias_cache = self.beta_2 * layer.bias_cache + (1 - self.beta_2) * layer.dbiases**2\n",
        "        # Get corrected cache\n",
        "        weight_cache_corrected = layer.weight_cache / (1 - self.beta_2 ** (self.iterations + 1))\n",
        "        bias_cache_corrected = layer.bias_cache / (1 - self.beta_2 ** (self.iterations + 1))\n",
        "\n",
        "        # Vanilla SGD parameter update + normalization\n",
        "        # with square rooted cache\n",
        "        layer.weights += -self.current_learning_rate * weight_momentums_corrected / (np.sqrt(weight_cache_corrected) + self.epsilon)\n",
        "        layer.biases += -self.current_learning_rate * bias_momentums_corrected / (np.sqrt(bias_cache_corrected) + self.epsilon)\n",
        "\n",
        "    # Call once after any parameter updates\n",
        "    def post_update_params(self):\n",
        "        self.iterations += 1\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "M_e3ugVeorqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a Neural Network and Training"
      ],
      "metadata": {
        "id": "tligNO7js1um"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#creating a neural Network\n",
        "dense1 = Layer_Dense(17, 128)\n",
        "activation1 = Activation_ReLU()\n",
        "dense2 = Layer_Dense( 128 , 64 )\n",
        "activation2 = Activation_ReLU()\n",
        "dense3 = Layer_Dense( 64 , 6)\n",
        "activation3 = Activation_Softmax()\n",
        "\n",
        "\n",
        "# Create optimizer\n",
        "optimizer = Optimizer_Adam(learning_rate = 0.02, decay = 1e-5)\n",
        "\n",
        "\n",
        "# Train in loop\n",
        "for epoch in range ( 5001 ):\n",
        "\n",
        "    ##training\n",
        "    dense1.forward(X_train)\n",
        "    activation1.forward(dense1.output)\n",
        "    dense2.forward(activation1.output)\n",
        "    activation2.forward(dense2.output)\n",
        "    dense3.forward(activation2.output)\n",
        "    activation3.forward(dense3.output)\n",
        "\n",
        "    loss = categorical_crossentropy_loss(activation3.output, y_train)\n",
        "    loss_grad = categorical_crossentropy_loss_gradient(activation3.output, y_train) #dvalues\n",
        "\n",
        "    predictions = np.argmax(activation3.output, axis = 1 )\n",
        "    if len (y_train.shape) == 2 :\n",
        "      y_train = np.argmax(y_train, axis = 1 )\n",
        "    accuracy = np.mean(predictions == y_train)\n",
        "\n",
        "    if not epoch % 100 :\n",
        "      print(f\"epoch:{epoch} ,acc:{accuracy:.3f} ,loss:{loss:.3f} ,lr:{optimizer.current_learning_rate}\")\n",
        "\n",
        "\n",
        "    # # Backward pass\n",
        "    activation3.backward(loss_grad)\n",
        "    dense3.backward(activation3.dinputs)\n",
        "    activation2.backward(dense3.dinputs)\n",
        "    dense2.backward(activation2.dinputs)\n",
        "    activation1.backward(dense2.dinputs)\n",
        "    dense1.backward(activation1.dinputs)\n",
        "\n",
        "    # Update weights and biases\n",
        "    optimizer.pre_update_params()\n",
        "    optimizer.update_params(dense1)\n",
        "    optimizer.update_params(dense2)\n",
        "    optimizer.post_update_params()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bARdzNVn6H1",
        "outputId": "c848f263-7d9b-4786-ac91-12a801b39737"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:0 ,acc:0.170 ,loss:3.615 ,lr:0.02\n",
            "epoch:100 ,acc:0.559 ,loss:1.111 ,lr:0.01998021958261321\n",
            "epoch:200 ,acc:0.729 ,loss:0.806 ,lr:0.019960279044701046\n",
            "epoch:300 ,acc:0.809 ,loss:0.665 ,lr:0.019940378268975763\n",
            "epoch:400 ,acc:0.820 ,loss:0.545 ,lr:0.01992051713662487\n",
            "epoch:500 ,acc:0.862 ,loss:0.457 ,lr:0.01990069552930875\n",
            "epoch:600 ,acc:0.878 ,loss:0.407 ,lr:0.019880913329158343\n",
            "epoch:700 ,acc:0.900 ,loss:0.356 ,lr:0.019861170418772778\n",
            "epoch:800 ,acc:0.907 ,loss:0.344 ,lr:0.019841466681217078\n",
            "epoch:900 ,acc:0.906 ,loss:0.291 ,lr:0.01982180200001982\n",
            "epoch:1000 ,acc:0.901 ,loss:0.273 ,lr:0.019802176259170884\n",
            "epoch:1100 ,acc:0.892 ,loss:0.287 ,lr:0.01978258934311912\n",
            "epoch:1200 ,acc:0.956 ,loss:0.191 ,lr:0.01976304113677013\n",
            "epoch:1300 ,acc:0.957 ,loss:0.175 ,lr:0.019743531525483964\n",
            "epoch:1400 ,acc:0.964 ,loss:0.159 ,lr:0.01972406039507293\n",
            "epoch:1500 ,acc:0.966 ,loss:0.137 ,lr:0.019704627631799327\n",
            "epoch:1600 ,acc:0.967 ,loss:0.131 ,lr:0.019685233122373254\n",
            "epoch:1700 ,acc:0.972 ,loss:0.124 ,lr:0.019665876753950384\n",
            "epoch:1800 ,acc:0.979 ,loss:0.101 ,lr:0.01964655841412981\n",
            "epoch:1900 ,acc:0.979 ,loss:0.093 ,lr:0.019627277990951823\n",
            "epoch:2000 ,acc:0.969 ,loss:0.099 ,lr:0.019608035372895814\n",
            "epoch:2100 ,acc:0.983 ,loss:0.085 ,lr:0.01958883044887805\n",
            "epoch:2200 ,acc:0.982 ,loss:0.075 ,lr:0.019569663108249594\n",
            "epoch:2300 ,acc:0.983 ,loss:0.069 ,lr:0.01955053324079414\n",
            "epoch:2400 ,acc:0.982 ,loss:0.065 ,lr:0.019531440736725945\n",
            "epoch:2500 ,acc:0.983 ,loss:0.063 ,lr:0.019512385486687673\n",
            "epoch:2600 ,acc:0.983 ,loss:0.060 ,lr:0.019493367381748363\n",
            "epoch:2700 ,acc:0.983 ,loss:0.054 ,lr:0.019474386313401298\n",
            "epoch:2800 ,acc:0.983 ,loss:0.051 ,lr:0.019455442173562\n",
            "epoch:2900 ,acc:0.983 ,loss:0.048 ,lr:0.019436534854566128\n",
            "epoch:3000 ,acc:0.993 ,loss:0.045 ,lr:0.01941766424916747\n",
            "epoch:3100 ,acc:0.559 ,loss:4.412 ,lr:0.019398830250535893\n",
            "epoch:3200 ,acc:0.971 ,loss:0.089 ,lr:0.019380032752255354\n",
            "epoch:3300 ,acc:0.975 ,loss:0.065 ,lr:0.01936127164832186\n",
            "epoch:3400 ,acc:0.984 ,loss:0.050 ,lr:0.01934254683314152\n",
            "epoch:3500 ,acc:0.993 ,loss:0.045 ,lr:0.019323858201528515\n",
            "epoch:3600 ,acc:0.993 ,loss:0.043 ,lr:0.019305205648703173\n",
            "epoch:3700 ,acc:0.984 ,loss:0.043 ,lr:0.01928658907028997\n",
            "epoch:3800 ,acc:0.993 ,loss:0.040 ,lr:0.01926800836231563\n",
            "epoch:3900 ,acc:0.993 ,loss:0.040 ,lr:0.019249463421207133\n",
            "epoch:4000 ,acc:0.995 ,loss:0.038 ,lr:0.019230954143789846\n",
            "epoch:4100 ,acc:0.995 ,loss:0.037 ,lr:0.019212480427285565\n",
            "epoch:4200 ,acc:0.995 ,loss:0.036 ,lr:0.019194042169310647\n",
            "epoch:4300 ,acc:0.995 ,loss:0.035 ,lr:0.019175639267874092\n",
            "epoch:4400 ,acc:0.995 ,loss:0.034 ,lr:0.019157271621375684\n",
            "epoch:4500 ,acc:0.995 ,loss:0.034 ,lr:0.0191389391286041\n",
            "epoch:4600 ,acc:0.995 ,loss:0.032 ,lr:0.019120641688735073\n",
            "epoch:4700 ,acc:0.995 ,loss:0.032 ,lr:0.019102379201329525\n",
            "epoch:4800 ,acc:0.993 ,loss:0.031 ,lr:0.01908415156633174\n",
            "epoch:4900 ,acc:0.993 ,loss:0.031 ,lr:0.01906595868406753\n",
            "epoch:5000 ,acc:0.995 ,loss:0.029 ,lr:0.01904780045524243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XPXFFtNgoa80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing our trained Neural Network"
      ],
      "metadata": {
        "id": "Sztx1km5s_e1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#testing neural network\n",
        "\n",
        "dense1.forward(X_test)\n",
        "activation1.forward(dense1.output)\n",
        "dense2.forward(activation1.output)\n",
        "activation2.forward(dense2.output)\n",
        "dense3.forward(activation2.output)\n",
        "activation3.forward(dense3.output)\n",
        "\n",
        "loss = categorical_crossentropy_loss(activation3.output, y_test)\n",
        "loss_grad = categorical_crossentropy_loss_gradient(activation3.output, y_test) #dvalues\n",
        "\n",
        "predictions = np.argmax(activation3.output, axis = 1 )\n",
        "if len (y_test.shape) == 2 :\n",
        "  y_test = np.argmax(y_test, axis = 1 )\n",
        "accuracy = np.mean(predictions == y_test)\n",
        "\n",
        "print(f\"acc:{accuracy:.3f} ,loss:{loss:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MYvRL0foa5S",
        "outputId": "7165f324-3d0b-440b-9ba9-be8e80b32403"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc:0.961 ,loss:0.402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r9OyWOVdoa2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ctjjLKtWoazY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
